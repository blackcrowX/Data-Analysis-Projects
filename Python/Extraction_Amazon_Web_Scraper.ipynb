{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMof4sQLlaPlq9y9ckVpZDU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackcrowX/Data_Analytics_Projects/blob/main/Python/Extraction_Amazon_Web_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "<h1>Extraction - Amazon Web Scraper</h1>\n",
        "<img src=\"https://i.postimg.cc/K8mbkyhz/Logo-Black.png\"/>\n",
        "</div>"
      ],
      "metadata": {
        "id": "Z2-O2oH73HSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "* Introduction\n",
        "* Setup\n",
        "  * Import Libraries\n",
        "  * Extract Data\n",
        "* XYZ\n",
        "  * XYZ"
      ],
      "metadata": {
        "id": "MCewidGz2wDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\">Introduction</h1>\n",
        "\n",
        "We will analyze a dataset of the global average sea level change since 1880. We will use the data to predict the sea level change through year 2050. The dataset was published by <a href=\"https://www.freecodecamp.org/learn/data-analysis-with-python/data-analysis-with-python-projects/sea-level-predictor\">freeCodeCamp</a>."
      ],
      "metadata": {
        "id": "S9aliKJm251d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\">Setup</h1>"
      ],
      "metadata": {
        "id": "q6uoGcKg25lq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Import Libraries\n",
        "\n",
        "Import and configure libraries required for data extraction."
      ],
      "metadata": {
        "id": "7V721Bfu2-T6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import smtplib"
      ],
      "metadata": {
        "id": "U0h63HWO5vTa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Extract Data\n",
        "\n",
        "Use Beautifulsoup to extract the data from `amazon.com`."
      ],
      "metadata": {
        "id": "a09JTkiy2qFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.amazon.de/-/en/gp/product/B09X6T1RLM/\"\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "html = requests.get(url, headers=headers)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "print(html.text)"
      ],
      "metadata": {
        "id": "EzkUIisSZPTG",
        "outputId": "63638ee8-a263-46c1-d11b-4c11e8630bd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html>\n",
            "<head>\n",
            "    <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n",
            "    <meta charset=\"utf-8\">\n",
            "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\n",
            "<title>\n",
            "Tut uns Leid!\n",
            "</title>\n",
            "\n",
            "<style type=\"text/css\"><!--\n",
            ".serif { font-family: times,serif; font-size: small; }\n",
            ".sans { font-family: verdana,arial,helvetica,sans-serif; font-size: small; }\n",
            ".small { font-family: verdana,arial,helvetica,sans-serif; font-size: x-small; }\n",
            ".h1 { font-family: verdana,arial,helvetica,sans-serif; color: #CC6600; font-size: small; }\n",
            ".h3color { font-family: verdana,arial,helvetica,sans-serif; color: #CC6600; font-size: x-small; }\n",
            ".tiny { font-family: verdana,arial,helvetica,sans-serif; font-size: xx-small; }\n",
            ".listprice { font-family: arial,verdana,helvetica,sans-serif; text-decoration: line-through; font-size: x-small; }\n",
            ".price { font-family: verdana,arial,helvetica,sans-serif; color: #990000; font-size: x-small; }\n",
            "--></style>\n",
            "</head>\n",
            "\n",
            "<body bgcolor=\"#FFFFFF\" link=\"#003399\" alink=\"#FF9933\" vlink=\"#996633\" text=\"#000000\">\n",
            "\n",
            "<!--\n",
            "        To discuss automated access to Amazon data please contact api-services-support@amazon.com.\n",
            "        For information about migrating to our APIs refer to our Marketplace APIs at https://developer.amazonservices.de/ref=rm_5_sv, or our Product Advertising API at https://partnernet.amazon.de/gp/advertising/api/detail/main.html/ref=rm_5_ac for advertising use cases.\n",
            "-->\n",
            "\n",
            "<center>\n",
            "<a href=\"https://www.amazon.de/ref=cs_503_logo/\">\n",
            "<img src=\"https://images-eu.ssl-images-amazon.com/images/G/03/general/de-logo-153x37.gif\" width=153 height=37 alt=\"Amazon.de\" border=0></a>\n",
            "<p>\n",
            "\n",
            "<table cellpadding=3 width=\"90%\" bgcolor=#ffffff border=0 cellspacing=\"2\" align=\"center\">\n",
            "<tr>\n",
            "<td>\n",
            "<h2>Tut uns Leid!</h2>\n",
            "\n",
            "\n",
            "W&auml;hrend wir Ihre Eingabe ausf&uuml;hren wollten, ist ein technischer Fehler aufgetreten. Wir arbeiten bereits daran und werden sobald wie m&ouml;glich wieder f&uuml;r Sie da sein. Bitte schauen Sie sp&auml;ter wieder vorbei.<p>\n",
            "\n",
            "F&uuml;r diese Unannehmlichkeit bitten wir Sie vielmals um Entschuldigung und danken f&uuml;r Ihr Verst&auml;ndnis.<p>\n",
            "\n",
            "Ihr Team von Amazon.de\n",
            "\n",
            "</td></tr>\n",
            "</table>\n",
            "<b><a href=\"https://www.amazon.de/ref=cs_503_link/\">Klicken Sie hier, um zur&uuml;ck zur Homepage Amazon.de</a></b>\n",
            "</center>\n",
            "\n",
            "</body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IQYWDcFz2Hsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8674ec-79c5-4ce4-c982-923154e5ca84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price: None\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.amazon.de/-/en/gp/product/B09X6T1RLM/ref=ewc_pr_img_1?smid=A3JI6PN5RO1TLK&psc=1\"\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Create a BeautifulSoup object with the response text\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find the price element and extract the price\n",
        "price_element = soup.find(\"span\", {\"class\": \"a-offscreen\"})\n",
        "price = price_element\n",
        "\n",
        "print(\"Price:\", price)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL = 'https://www.amazon.com/Amazon-Basics-Ply-Paper-Towel/dp/B09BWFX1L6/ref=sr_1_3?crid=3DY5V5GYXFRE1&keywords=amazon+basic&qid=1684171403&sprefix=amazon+basi%2Caps%2C349&sr=8-3'\n",
        "\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "\n",
        "page = requests.get(URL, headers=headers)\n",
        "\n",
        "soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
        "\n",
        "title = soup2.find(id='corePrice_feature_div').get_text()\n",
        "\n",
        "price = soup2.find(id='priceblock_ourprice').get_text()\n",
        "\n",
        "\n",
        "print(title)\n",
        "print(price)"
      ],
      "metadata": {
        "id": "1b4BzAd0laSC",
        "outputId": "ac0c9ce9-ff19-42c2-84ce-fc885b338d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-23088babf7ba>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msoup2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprettify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'corePrice_feature_div'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'priceblock_ourprice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "<span id=\"productTitle\" class=\"a-size-medium product-title-word-break product-title-resize\">        BRITA filter cartridges MAXTRA + 12 Pack - cartridge for all BRITA water filters to reduce lime, chlorine &amp; taste-disturbing substances in tap water       </span>"
      ],
      "metadata": {
        "id": "xTZD7EKnlMoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\">Data Extraction</h1>"
      ],
      "metadata": {
        "id": "A939rUL_3tIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Data Cleaning\n",
        "\n",
        "Let's clean up the data a little bit."
      ],
      "metadata": {
        "id": "A9d7jI-DVVBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title = title.strip()[1:]\n",
        "price = price.strip()[1:]\n",
        "\n",
        "print(title)\n",
        "print(price)"
      ],
      "metadata": {
        "id": "3Zj0WNVpVVU5",
        "outputId": "5ebcf0f2-ff0b-4bdb-8958-caf36405be8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mazon Basics 2-Ply Paper Towels, Flex-Sheets, 6 Rolls (Pack of 2), 12 Value Rolls total (Previously Solimo)\n",
            "9.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Timestamp for your output to track when data was collected\n",
        "\n",
        "import datetime\n",
        "\n",
        "today = datetime.date.today()\n",
        "\n",
        "print(today)"
      ],
      "metadata": {
        "id": "WM63zPyKdSjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CSV and write headers and data into the file\n",
        "\n",
        "import csv \n",
        "\n",
        "header = ['Title', 'Price', 'Date']\n",
        "data = [title, price, today]\n",
        "\n",
        "\n",
        "with open('AmazonWebScraperDataset.csv', 'w', newline='', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerow(data)"
      ],
      "metadata": {
        "id": "Es0KxymddT6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(r'C:\\Users\\alexf\\AmazonWebScraperDataset.csv')\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "G19abIC-dVhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we are appending data to the csv\n",
        "\n",
        "with open('AmazonWebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(data)"
      ],
      "metadata": {
        "id": "r8FOyPdsdXEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine all of the above code into one function\n",
        "\n",
        "\n",
        "def check_price():\n",
        "    URL = 'https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_3?dchild=1&keywords=data%2Banalyst%2Btshirt&qid=1626655184&sr=8-3&customId=B0752XJYNL&th=1'\n",
        "\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "\n",
        "    page = requests.get(URL, headers=headers)\n",
        "\n",
        "    soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "    soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
        "\n",
        "    title = soup2.find(id='productTitle').get_text()\n",
        "\n",
        "    price = soup2.find(id='priceblock_ourprice').get_text()\n",
        "\n",
        "    price = price.strip()[1:]\n",
        "    title = title.strip()\n",
        "\n",
        "    import datetime\n",
        "\n",
        "    today = datetime.date.today()\n",
        "    \n",
        "    import csv \n",
        "\n",
        "    header = ['Title', 'Price', 'Date']\n",
        "    data = [title, price, today]\n",
        "\n",
        "    with open('AmazonWebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(data)"
      ],
      "metadata": {
        "id": "CjONNRfsdY5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Runs check_price after a set time and inputs data into your CSV\n",
        "\n",
        "while(True):\n",
        "    check_price()\n",
        "    time.sleep(86400)"
      ],
      "metadata": {
        "id": "9yQnYxijdbGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(r'C:\\Users\\alexf\\AmazonWebScraperDataset.csv')\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "K07DPwZ6dct0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If uou want to try sending yourself an email (just for fun) when a price hits below a certain level you can try it\n",
        "# out with this script\n",
        "\n",
        "def send_mail():\n",
        "    server = smtplib.SMTP_SSL('smtp.gmail.com',465)\n",
        "    server.ehlo()\n",
        "    #server.starttls()\n",
        "    server.ehlo()\n",
        "    server.login('AlexTheAnalyst95@gmail.com','xxxxxxxxxxxxxx')\n",
        "    \n",
        "    subject = \"The Shirt you want is below $15! Now is your chance to buy!\"\n",
        "    body = \"Alex, This is the moment we have been waiting for. Now is your chance to pick up the shirt of your dreams. Don't mess it up! Link here: https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_3?dchild=1&keywords=data+analyst+tshirt&qid=1626655184&sr=8-3\"\n",
        "   \n",
        "    msg = f\"Subject: {subject}\\n\\n{body}\"\n",
        "    \n",
        "    server.sendmail(\n",
        "        'AlexTheAnalyst95@gmail.com',\n",
        "        msg\n",
        "     \n",
        "    )"
      ],
      "metadata": {
        "id": "vFlY7OQ4deY5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}