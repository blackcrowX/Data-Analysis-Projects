{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXEoDWPv3D/nYjePmZ1r5L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackcrowX/Data-Analyst-Projects/blob/main/SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqPner9mUU1X"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pd_to_sqlDB(input_df: pd.DataFrame,\n",
        "                table_name: str,\n",
        "                db_name: str = 'default.db') -> None:\n",
        "\n",
        "    '''Take a Pandas dataframe `input_df` and upload it to `table_name` SQLITE table\n",
        "    Args:\n",
        "        input_df (pd.DataFrame): Dataframe containing data to upload to SQLITE\n",
        "        table_name (str): Name of the SQLITE table to upload to\n",
        "        db_name (str, optional): Name of the SQLITE Database in which the table is created. \n",
        "                                 Defaults to 'default.db'.\n",
        "    '''\n",
        "\n",
        "    # Step 1: Setup local logging\n",
        "    import logging\n",
        "    logging.basicConfig(level=logging.INFO,\n",
        "                        format='%(asctime)s %(levelname)s: %(message)s',\n",
        "                        datefmt='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # Step 2: Find columns in the dataframe\n",
        "    cols = input_df.columns\n",
        "    cols_string = ','.join(cols)\n",
        "    val_wildcard_string = ','.join(['?'] * len(cols))\n",
        "\n",
        "    # Step 3: Connect to a DB file if it exists, else crete a new file\n",
        "    con = sqlite3.connect(db_name)\n",
        "    cur = con.cursor()\n",
        "    logging.info(f'SQL DB {db_name} created')\n",
        "\n",
        "    # Step 4: Create Table\n",
        "    sql_string = f\"\"\"CREATE TABLE {table_name} ({cols_string});\"\"\"\n",
        "    cur.execute(sql_string)\n",
        "    logging.info(f'SQL Table {table_name} created with {len(cols)} columns')\n",
        "\n",
        "    # Step 5: Upload the dataframe\n",
        "    rows_to_upload = input_df.to_dict(orient='split')['data']\n",
        "    sql_string = f\"\"\"INSERT INTO {table_name} ({cols_string}) VALUES ({val_wildcard_string});\"\"\"    \n",
        "    cur.executemany(sql_string, rows_to_upload)\n",
        "    logging.info(f'{len(rows_to_upload)} rows uploaded to {table_name}')\n",
        "  \n",
        "    # Step 6: Commit the changes and close the connection\n",
        "    con.commit()\n",
        "    con.close()"
      ],
      "metadata": {
        "id": "bI8qe9QFWZEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sql_query_to_pd(sql_query_string: str, db_name: str ='default.db') -> pd.DataFrame:\n",
        "    '''Execute an SQL query and return the results as a pandas dataframe\n",
        "    Args:\n",
        "        sql_query_string (str): SQL query string to execute\n",
        "        db_name (str, optional): Name of the SQLITE Database to execute the query in.\n",
        "                                 Defaults to 'default.db'.\n",
        "    Returns:\n",
        "        pd.DataFrame: Results of the SQL query in a pandas dataframe\n",
        "    '''    \n",
        "    # Step 1: Connect to the SQL DB\n",
        "    con = sqlite3.connect(db_name)\n",
        "\n",
        "    # Step 2: Execute the SQL query\n",
        "    cursor = con.execute(sql_query_string)\n",
        "\n",
        "    # Step 3: Fetch the data and column names\n",
        "    result_data = cursor.fetchall()\n",
        "    cols = [description[0] for description in cursor.description]\n",
        "\n",
        "    # Step 4: Close the connection\n",
        "    con.close()\n",
        "\n",
        "    # Step 5: Return as a dataframe\n",
        "    return pd.DataFrame(result_data, columns=cols)"
      ],
      "metadata": {
        "id": "4exK_PdGWbGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Read the csv file into a dataframe\n",
        "# Dataset from https://www.kaggle.com/gpreda/covid-world-vaccination-progress\n",
        "input_df = pd.read_csv('country_vaccinations.csv')\n",
        "\n",
        "# Step 2: Upload the dataframe to a SQL Table\n",
        "pd_to_sqlDB(input_df,\n",
        "            table_name='country_vaccinations',\n",
        "            db_name='default.db')\n",
        "\n",
        "# Step 3: Write the SQL query in a string variable\n",
        "sql_query_string = \"\"\"\n",
        "    SELECT country, SUM(daily_vaccinations) as total_vaccinated\n",
        "    FROM country_vaccinations \n",
        "    WHERE daily_vaccinations IS NOT NULL \n",
        "    GROUP BY country\n",
        "    ORDER BY total_vaccinated DESC\n",
        "\"\"\"\n",
        "\n",
        "# Step 4: Exectue the SQL query\n",
        "result_df = sql_query_to_pd(sql_query_string, db_name='default.db')\n",
        "result_df"
      ],
      "metadata": {
        "id": "vCQFKpNeWbRQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}